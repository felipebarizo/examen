---
title: "Tarea Individual II"
subtitle: "Ciencia de Datos con R"
format: html
editor: visual
---

## Introducción

El objetivo de esta tarea es aplicar técnicas de **aprendizaje supervisado** utilizando `tidymodels`. Se plantean dos problemas: uno de **regresión** y otro de **clasificación**, utilizando modelos de **árbol de decisión** y **random forest**. Además, se debe interpretar y comunicar los resultados obtenidos.

## Parte 1 – Regresión

**Dataset:** `ames` (paquete `{modeldata}`)\
**Variable objetivo:** `Sale_Price` (precio de venta de la vivienda)

### 1.1 Preparación de datos

1.1.1. Cargar el dataset `ames` y convertirlo en tibble. Guardar como `ames_data`.

```{r, include=FALSE}
#| label: ejercicio_111
library(tidyverse)
library(tidymodels)
library(kernlab)
library(rpart.plot)
library(vip)
library(modeldata)
library(tidyverse)
data(ames)
ames_data <- as_tibble(ames)
```

1.1.2. Utilizar `Sale_Price` como variable respuesta. Guarda la formula como `formula_ames`.

```{r}
#| label: ejercicio_112
formula_ames <- Sale_Price ~.
```

1.1.3. Dividir los datos en entrenamiento (80%) y test (20%). Guarda los conjuntos como `ames_train` y `ames_test`.

```{r}
#| label: ejercicio_113
ames_split <- initial_split(ames_data, prop = 0.8)
ames_train <- training(ames_split)
ames_test  <- testing(ames_split)
```

### 1.2 Entrenamiento del modelo

1.2.1. Definir un modelo de árbol de decisión. Guardar como `tree_ames`.

```{r}
#| label: ejercicio_121
tree_ames <- decision_tree() |>
  set_mode("regression") |>
  set_engine("rpart")
```

1.2.2. Entrenar el modelo utilizando `fit()`. Guardar el modelo entrenado como `fit_tree_ames`.

```{r}
#| label: ejercicio_122
fit_tree_ames <-fit(tree_ames,formula_ames, data = ames_train)

```

### 1.3 Evaluación del modelo

1.3.1. Predecir sobre el conjunto de test. Guardar las predicciones como `predictions_ames`.

```{r}
#| label: ejercicio_131
predictions_ames <- predict(fit_tree_ames, ames_test) |> bind_cols(ames_test)
```

1.3.2. Calcular **RMSE** y **R²** tanto para train y test. En el caso de `ames_train` guardar como `metrics_train_ames` y en el caso de `ames_test` como `metrics_test_ames`.

```{r}
#| label: ejercicio_132
 metrics_test_ames <- metrics(predictions_ames, truth = Sale_Price, estimate = .pred) |> filter(.metric %in% c("rmse","rsq"))

predictions_ames1 <- predict(fit_tree_ames, ames_train) |> bind_cols(ames_train)

metrics_train_ames <- metrics(predictions_ames1, truth = Sale_Price, estimate = .pred) |> filter(.metric %in% c("rmse","rsq"))

```

1.3.3. Graficar valores reales vs. estimados (`Sale_Price`) con línea de identidad, utilizando los datos de entrenamiento. Mostrar el gráfico y guardarlo como `plot_tree_ames`.

```{r}
#| label: ejercicio_133
plot_tree_ames <- ggplot(predictions_ames1, aes(x = Sale_Price, y = .pred)) +
  geom_point(alpha = 0.5, color = "steelblue") +           
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(
    title = "Valores reales vs. predichos",
    x = "Valor real",
    y = "Valor predicho"
  ) +
  theme_minimal()
```

1.3.4. Interpretar las métricas y el gráfico. (En este caso, no es necesario un chunk de código, pero sí una breve explicación en el texto).

***Respuesta:***

Para los datos de test el 71,9% de la variabilidad de Sales_Price es explicada por el modelo y para los datos de train el 76,7% de la variabilidad de Sales_Price es explicada por el modelo.

Por otro lado podemos ver (en relación al rmse) que en promedio el modelo se equivoca en 40mil dólares al predecir el precio de una vivienda.

El gráfico nos muestra los datos predichos contra los datos ideales, en este caso los valores altos se tienden a subestimar, por lo que podemos decir que el modelo tiene deificultad para caputrar los valores altos.

1.3.5. Evaluar si hay sobreajuste o subajuste. Esta respuesta es libre y puede realizar el códogo que considere necesario para evaluar el modelo.

***Respuesta:***

La diferencia entre las métricas no es demasiado grande, lo que indica que no hay un sobreajuste fuerte. Tampoco podemos afirmar que haya subajuste dado que el R2 es bastante alto y el error no es muy alto.

### 1.4 Interpretación del árbol

1.4.1. Visualizar el árbol. Guardar el gráfico como `plot_tree_ames_final`.

```{r}
#| label: ejercicio_141
plot_tree_ames_final <- rpart.plot(fit_tree_ames$fit)
```

1.4.2. Interpretar brevemente las decisiones del árbol.

***Respuesta:***

Este árbol nos idica las principales variables que influyen en el precio de venta de un hogar.

Primero el árbol divide a la muestra entre dos grupos grandes, los divide por barrios, es decir, donde se encuentra ubicada la vivienda (una con precios más altos y otra con menos).

Luego divide entre diferentes grupo la vivienda, divide por un lado entre la superficie de dicha casa y por otro lado genera otro nodo que divide entre la superficie del sótano de la vivienda

------------------------------------------------------------------------

## Parte 2 – Clasificación

**Dataset:** `attrition` (paquete `{modeldata}`)\
**Variable objetivo:** `Attrition` (abandono laboral: "Yes" o "No")

### 2.1 Preparación de datos

2.1.1. Cargar el dataset `attrition` y convertirlo en tibble. Guardar como `attrition_data`.

```{r}
#| label: ejercicio_211
data("attrition")
attrition_data <- as_tibble(attrition)

```

2.1.2. Asegurarse de que `Attrition` sea un factor. Sobreescribir la variable si es necesario.

```{r}
#| label: ejercicio_212
class(attrition_data$Attrition)

```

2.1.3. Dividir los datos en entrenamiento (80%) y test (20%) manteniendo la misma proporción de clases en ambos datasets. Guarda los conjuntos como `attrition_train` y `attrition_test`.

```{r}
#| label: ejercicio_213
attrition_split <- initial_split(attrition_data, prop = 0.8)
attrition_train  <- training(attrition_split)
attrition_test  <- testing(attrition_split)
```

### 2.2 Entrenamiento del modelo

2.2.1. Definir un modelo de random forest. Llevar a cabo la definición utilizando `rand_forest()` y `set_engine()`. Guardar como `rf_attrition`.

```{r}
#| label: ejercicio_221
rf_attrition <- rand_forest(trees = 500, min_n = 5) |>
  set_mode("classification") |>
  set_engine("ranger", importance = "impurity")
```

2.2.2. Entrenar el modelo. Llevar a cabo el entrenamiento utilizando `fit()`. Utilizar la fórmula `Attrition ~ .` para incluir todas las variables predictoras. Guardar el modelo entrenado como `fit_rf_attrition`.

```{r}
#| label: ejercicio_222
fit_rf_attrition <- fit(rf_attrition, Attrition ~ ., data = attrition_train)

```

### 2.3 Evaluación del modelo

2.3.1. Predecir sobre el conjunto de test. Guardar las predicciones como `predictions_attrition`.

```{r}
#| label: ejercicio_231
predictions_attrition <- predict(fit_rf_attrition, attrition_test, type = "class") |>bind_cols(truth = attrition_test$Attrition)
```

2.3.2. Calcular **accuracy**, **precision**, **recall** y **F1**. Guardar las métricas de entrenamiento como `metrics_train_attrition` y las de test como `metrics_test_attrition`.

```{r}
#| label: ejercicio_232
metrics_test_attrition <- metric_set(accuracy, precision, recall, f_meas)(
  predictions_attrition, truth = truth, estimate = .pred_class
)


predictions_attrition1 <- predict(fit_rf_attrition, attrition_train, type = "class") |>bind_cols(truth = attrition_train$Attrition)

metrics_train_attrition <- metric_set(accuracy, precision, recall, f_meas)(
  predictions_attrition1, truth = truth, estimate = .pred_class
)
```

2.3.3. Visualizar matriz de confusión con `autoplot(type = "heatmap")`. Imprimir el gráfico y guardarlo como `plot_confusion_attrition`.

```{r}
#| label: ejercicio_233
plot_confusion_attrition <- conf_mat(predictions_attrition1, truth = truth, estimate = .pred_class) |>
  autoplot(type = "heatmap") +
  scale_fill_gradient(low = "white", high = "red")

plot_confusion_attrition
```

2.3.4. Visualizar variables importantes con `vip()`. Imprimir el gráfico y guardarlo como `plot_vip_attrition`.

```{r}
#| label: ejercicio_234
modelo_rf <- extract_fit_engine(fit_rf_attrition)
plot_vip_attrition <- vip(modelo_rf)
plot_vip_attrition
```

2.3.5. Interpretar las métricas y los errores. (En este caso, no es necesario un chunk de código, pero sí una breve explicación en el texto).

**Respuesta:**

***Para test***

|           |        |           |     |     |
|-----------|--------|-----------|-----|-----|
|           |        |           |     |     |
| accuracy  | binary | 0.8537415 |     |     |
| precision | binary | 0.8541667 |     |     |
| recall    | binary | 0.9959514 |     |     |
| f_meas    | binary | 0.9196262 |     |     |

El 85,37% de las prediciones del conjunto de test fueron correctas.

De todas las veces que el modelo predijo "Sí" , acertó el 85.41667%.

De todos los empleados que efectivamente renunciaron, el modelo identificó correctamente al 99.6%.

El promedio armónico entre la precisión y la sensibilidad, es bastante alto, lo que indica buen equilibrio.

***Para train:***

|           |        |           |     |     |
|-----------|--------|-----------|-----|-----|
|           |        |           |     |     |
| accuracy  | binary | 0.9957483 |     |     |
| precision | binary | 0.9949546 |     |     |
| recall    | binary | 1.0000000 |     |     |
| f_meas    | binary | 0.9974709 |     |     |

El 99,57% de las prediciones del conjunto de test fueron correctas.

De todas las veces que el modelo predijo "Sí" , acertó el 99,5%.

De todos los empleados que efectivamente renunciaron, el modelo identificó correctamente al 100%.

El promedio armónico entre la precisión y la sensibilidad, es bastante alto 99,74%, lo que indica buen equilibrio

2.3.6. Evaluar si hay sobreajuste o subajuste. Esta respuesta es libre y puede realizar el código que considere necesario para evaluar el modelo.

***Respuesta:***

El modelo tiene un desempeño perfecto casi perfecto en entrenamiento pero cuando se realiza el test cae el rendimiento notablemente aunque sigue siendo bastante bueno, esto es clara señal de sobreajuste.

------------------------------------------------------------------------

## Entrega

-   **La fecha limite de entrega es el 20 de junio de 2025.**

-   Las respuestas deben estar en este mismo archivo `.qmd`, el contenido deber ser completamente reproducible, es decir, cada `chunk` debe de funcionar sin errores para poder replicar los resultados.

-   No se aceptan archivos `.Rmd` o `.R` para la entrega. Solamente subir al repositorio el archivo `.qmd`con las respuestas.

-   Cada respuesta del ejercicio debe estar en el chunk correspondiente, no borrar la etiqueta del chunk `#| label: ejercicio_XX`.

-   Puede realizar pasos intermedios los que sean necesarios dentro del chunk pero debe de respetar el nombre del objeto final en el caso que se indique.

-   Los gráficos deben ser guardados en objetos y luego impresos en el caso que se indique que lo almacenen en un objeto. En el caso que no se indique, pueden ser impresos directamente.

-   Para comenzar la tarea deben de ir al siguiente link: GitHub Classroom. Una vez allí les va a pedir que indiquen su cuenta de GitHub y luego les va a crear un repositorio en su cuenta. Una vez creado el repositorio, deben de clonar el repositorio en su computadora y abrirlo con RStudio
